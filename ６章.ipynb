{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "６章.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utree/deeplearning2_colab_log/blob/master/%EF%BC%96%E7%AB%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mAqT1y-Gzxkc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ゲート付きRNN\n",
        "\n",
        "前章までのRNNをエルマン(Elman)と呼ぶ\n",
        "エルマンは性能が良くない\n",
        "\n",
        "問題点\n",
        "- 時系列データの長期の依存関係を学習できないから\n",
        "\n",
        "解決策\n",
        "- 「ゲート」と呼ばれる仕組みを導入する\n",
        "- ゲートを実装したRNNには、LSTMやGRUがある\n"
      ]
    },
    {
      "metadata": {
        "id": "4RIeaCuk0cuK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## エルマンではなぜ、長期記憶が出来ないか？\n",
        "- 勾配消失、勾配爆発が起こるから\n",
        "\n",
        "## 勾配消失もしくは勾配爆発の原因\n",
        "- "
      ]
    },
    {
      "metadata": {
        "id": "-CCbopxh4Zyb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QeUxrmXq5ZpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "536412b5-d954-4c98-9985-6388382e2f5d"
      },
      "cell_type": "code",
      "source": [
        "x = np.linspace(0, 3)\n",
        "y = 3*x + 4\n",
        "\n",
        "plt.plot(x, y, \"-\")\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFKCAYAAABcq1WoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI3wBAHAxwhcAABf7/5lLKe4a6Na/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Qv0sFx136aTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "658ecdc6-9886-472c-ac53-247e9d230cf0"
      },
      "cell_type": "code",
      "source": [
        "x1 = np.linspace(-5, 5)\n",
        "y1 = np.tanh(x1)\n",
        "\n",
        "plt.plot(x1, y1, \"-\")\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFKCAYAAAAwrQetAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "x4kK0GofZvV2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tanh関数の微分\n",
        "def tanh_derivative(x):\n",
        "  y = 4 / (np.exp(x) + np.exp(-x)) ** 2\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UOMI3w_AZ5ZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "3a67f6cd-4df2-4f1b-8dd9-3f4882eb9129"
      },
      "cell_type": "code",
      "source": [
        "x2 = np.linspace(-5, 5)\n",
        "y2 = tanh_derivative(x2)\n",
        "\n",
        "\n",
        "plt.plot(x1, y1, color='blue',  linestyle='solid')\n",
        "plt.plot(x2, y2, color='orange',  linestyle='dashed')\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFKCAYAAAAwrQetAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpZQaYuIiFhCpS0iImIJlbaIiIglfgEsapWQI6zLNgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "92M7bjrG1wwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記の式からも分かるように、\n",
        "tanh(x)の微分の式では、xが0から遠ざかるにつれて、値が小さくなる。\n"
      ]
    },
    {
      "metadata": {
        "id": "c0bLV6642PqM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MatMulノードの逆伝播では、時系列データの時間サイズ分だけ、毎回転置行列の積が掛けられる。"
      ]
    },
    {
      "metadata": {
        "id": "_7QE0kCK04aF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "3c39234c-c9c0-4d79-d827-ae602ced4a5d"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N = 2 # ミニバッチサイズ\n",
        "H = 3 # 隠れ状態ベクトルの次元数\n",
        "T = 20 # 時系列データの長さ\n",
        "\n",
        "dh = np.ones((N, H))\n",
        "np.random.seed(3) # 再現性のため乱数のシードを固定\n",
        "# Wh = np.random.randn(H, H)\n",
        "Wh = np.random.randn(H, H) * 0.5\n",
        "\n",
        "norm_list = []\n",
        "for t in range(T):\n",
        "  dh = np.dot(dh, Wh.T)\n",
        "  norm = np.sqrt(np.sum(dh**2)) / N \n",
        "  norm_list.append(norm)\n",
        "  #   norm_list.append(dh)\n",
        "  # dhは行列データなので、２乗の総和に平方根を適応して、平均値を求める\n",
        "\n",
        "# print(norm_list)\n",
        "\n",
        "# グラフの描画\n",
        "plt.plot(np.arange(len(norm_list)), norm_list)\n",
        "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
        "plt.xlabel('time step')\n",
        "plt.ylabel('norm')\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nolAQEZEUhYKIiKQoFEREJOX/AxGiX5AGGMZNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pscRttti7vGu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## L2ノルム\n",
        "各要素の2乗の総和に平方根を適応したもの"
      ]
    },
    {
      "metadata": {
        "id": "tkN5TEve2pow",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "逆伝播のMatMulノードの際、\n",
        "勾配dhの大きさは重みWhの値によって指数的に、増加、減少する\n",
        "\n",
        "※１より大きいとき、増加。１より小さい時減少"
      ]
    },
    {
      "metadata": {
        "id": "m_RFJVM88c-L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 勾配爆発への対策\n",
        "勾配爆発への対策は、勾配クリッピングという手法を用いる\n",
        "\n",
        "## 勾配クリッピングでは、\n",
        "勾配がしきい値以上のとき、勾配の値を\n",
        "\n",
        "g = threshold / |g| * g\n",
        "\n",
        "と設定する\n",
        "\n",
        "つまり、勾配を±(しきい値)と設定する"
      ]
    },
    {
      "metadata": {
        "id": "TZmJhNhUAIgp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## LSTMのインタフェース\n",
        "\n",
        "RNN(エルマン)では、入力行列hとxをMatMulで抽出し、バイアスと一緒に足し合わせ、活性化関数tanhに通していた。\n",
        "\n",
        "LSTMでも、入力行列hとx、バイアスをtanhに通す仕組みになっている。"
      ]
    },
    {
      "metadata": {
        "id": "cs8Dp8FyBDxw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "エルマンとLSTMのインターフェースの違いは、記憶セル:cという経路があること\n",
        "\n",
        "記憶セル:cには、過去から時刻tまでにおいて必要な情報が格納されている"
      ]
    },
    {
      "metadata": {
        "id": "YE6GPfj3CeAD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "記憶セル:cを用いて外部のレイヤへ状態hを出力する"
      ]
    },
    {
      "metadata": {
        "id": "JLsnNk5TCor5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "記憶セル:cは 3つの入力(Ct-1, Ht-1, Xt)から何らかの計算によって、算出される"
      ]
    },
    {
      "metadata": {
        "id": "FAFAgyodDF8K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "記憶セルCと隠れ状態Hの関係は\n",
        "H = tanh(C)\n",
        "である"
      ]
    },
    {
      "metadata": {
        "id": "TAebfsa1fAov",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## outputゲート\n",
        "次時刻の隠れ状態としてどれだけ重要かを調整する\n",
        "\n",
        "outputゲートの開き具合、次時刻へ状態hをどれだけ通すか?は次式の計算によって求める\n",
        "\n",
        "o = o(xW + hW + b)\n",
        "\n",
        "つまり、xWとhWとbの各要素の積によって、求める\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "HdNT8CRqfQiQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## forgetゲート\n",
        "\n",
        "何を忘れるかを明示的に指示するゲート\n",
        "\n",
        "Ct-1の記憶から、不要な記憶を忘れさせるゲート\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "st495rTTeilt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## アダマール積\n",
        "数学におけるアダマール積は、同じサイズの行列に対して、成分ごとに積を取ることによって定まる行列の積"
      ]
    },
    {
      "metadata": {
        "id": "_lFF84uSgApj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "X: 各単語データ\n",
        "H: 前時刻の状態\n",
        "C: 記憶"
      ]
    },
    {
      "metadata": {
        "id": "dNdGlalwhRVR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 新しい記憶gを生成するゲート\n",
        "新しい情報を生成する"
      ]
    },
    {
      "metadata": {
        "id": "9NFxS3HQi5yT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## inputゲート\n",
        "新たに追加する情報(gの各要素)が、新しい情報として、どれだけ価値があるかを判断するゲート"
      ]
    },
    {
      "metadata": {
        "id": "EnVx0liGjvHV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## アファイン変換\n",
        "平行移動と線形変換を組み合わせた変換のこと\n",
        "\n",
        "具体的には拡大、縮小、剪断、回転、平行移動"
      ]
    },
    {
      "metadata": {
        "id": "_kx4I3WXpi1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# common/config.py\n",
        "\n",
        "GPU = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Sm6Bc1ioxOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "7f05c979-cce0-42bf-b5ca-48ab281cd542"
      },
      "cell_type": "code",
      "source": [
        "# common/np.py\n",
        "\n",
        "# from common.config import GPU\n",
        "\n",
        "if GPU:\n",
        "  import cupy as np\n",
        "  np.cuda.set_allocator(np.cuda.MemoryPool().malloc)\n",
        "  np.add.at = np.scatter_add\n",
        "  \n",
        "  print('\\033[92m' + '-' * 60 + '\\033[0m]')\n",
        "  print(' ' * 23 + '\\033[92mGPU Mode (cupy)\\033[0m')\n",
        "  print('\\033[92m' + '-' * 60 + '\\033[0m\\n]')\n",
        "  \n",
        "else:\n",
        "  import numpy as np"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m------------------------------------------------------------\u001b[0m]\n",
            "                       \u001b[92mGPU Mode (cupy)\u001b[0m\n",
            "\u001b[92m------------------------------------------------------------\u001b[0m\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bb8A0nBvoW9-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# common/optimizer.py\n",
        "\n",
        "# from common.np import *\n",
        "\n",
        "class SGD:\n",
        "  '''\n",
        "  確率的勾配降下法\n",
        "  '''\n",
        "  def __init__(self, lr=0.01):\n",
        "    self.lr = lr\n",
        "    \n",
        "  def update(self, params, grads):\n",
        "    for i in range(len(params)):\n",
        "      params[i] -= self.lr * grads[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFcLhnhRudVZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# common/util.py\n",
        "import os\n",
        "\n",
        "def clip_grads(grads, max_norm):\n",
        "  total_norm = 0\n",
        "  for grad in grads:\n",
        "    total_norm += np.sum(grad ** 2)\n",
        "  total_norm = np.sqrt(total_norm)\n",
        "  \n",
        "  rate = max_norm / (total_norm + 1e-6)\n",
        "  if rate < 1:\n",
        "    for grad in grads:\n",
        "      grad *= rate\n",
        "      \n",
        "def eval_perplexity(model, corpus, batch_size=10, time_size=35):\n",
        "  print('evaluating perplexity ...')\n",
        "  corpus_size = len(corpus)\n",
        "  total_loss, loss_cnt = 0, 0\n",
        "  max_iters = (corpus_size - 1) // (batch_size * time_size)\n",
        "  jump = (corpus_size - 1) // batch_size\n",
        "  \n",
        "  for iters in range(max_iters):\n",
        "    xs = np.zeros((batch_size, time_size), dtype=np.int32)\n",
        "    ts = np.zeros((batch_size, time_size), dtype=np.int32)\n",
        "    time_offset = iters * time_size\n",
        "    offsets = [time_offset + (i * jump) for i in range(batch_size)]\n",
        "    for t in range(time_size):\n",
        "      for i, offset in enumerate(offsets):\n",
        "        xs[i, t] = corpus[(offset + t) % corpus_size]\n",
        "        ts[i, t] = corpus[(offset + t + 1) % corpus_size]\n",
        "        \n",
        "    try:\n",
        "      loss = model.forward(xs, ts, train_flg=False)\n",
        "    except TypeError:\n",
        "      loss = model.forward(xs, ts)\n",
        "    total_loss += loss\n",
        "    \n",
        "    sys.stdout.write('\\r%d / %d' % (iters, max_iters))\n",
        "    sys.stdout.flush()\n",
        "    \n",
        "  print('')\n",
        "  ppl = np.exp(total_loss / max_iters)\n",
        "  return ppl\n",
        "\n",
        "def to_cpu(x):\n",
        "  import numpy\n",
        "  if type(x) == numpy.ndarray:\n",
        "    return x\n",
        "  return np.asnumpy(x)\n",
        "\n",
        "def to_gpu(x):\n",
        "  import cupy\n",
        "  if type(x) == cupy.ndarray:\n",
        "    return x\n",
        "  return cupy.asarray(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C6cxlAA-psyB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# common/trainer.py\n",
        "\n",
        "import numpy\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "# from common.np import *\n",
        "# from common.util import clip_grads\n",
        "\n",
        "class RnnlmTrainer:\n",
        "  def __init__(self, model, optimizer):\n",
        "    self.model = model\n",
        "    self.optimizer = optimizer\n",
        "    self.time_idx = None\n",
        "    self.ppl_list = None\n",
        "    self.eval_interval = None\n",
        "    self.current_epoch = 0\n",
        "    \n",
        "  def get_batch(self, x, t, batch_size, time_size):\n",
        "    batch_x = np.empty((batch_size, time_size), dtype='i')\n",
        "    batch_t = np.empty((batch_size, time_size), dtype='i')\n",
        "    \n",
        "    data_size = len(x)\n",
        "    jump = data_size // batch_size\n",
        "    offsets = [i * jump for i in range(batch_size)] # バッチの各サンプルの読み込み開始位置\n",
        "    \n",
        "    for time in range(time_size):\n",
        "      for i, offset in enumerate(offsets):\n",
        "        batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
        "        batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
        "      self.time_idx += 1\n",
        "    return batch_x, batch_t\n",
        "  \n",
        "  def fit(self, xs, ts, max_epoch=10, batch_size=20, time_size=35, max_grad=None, eval_interval=20):\n",
        "    data_size = len(xs)\n",
        "    max_iters = data_size // (batch_size * time_size)\n",
        "    self.time_idx = 0\n",
        "    self.ppl_list = []\n",
        "    self.eval_interval = eval_interval\n",
        "    model, optimizer = self.model, self.optimizer\n",
        "    total_loss = 0\n",
        "    loss_count = 0\n",
        "    \n",
        "    start_time = time.time()\n",
        "    for epoch in range(max_epoch):\n",
        "      for iters in range(max_iters):\n",
        "        batch_x, batch_t = self.get_batch(xs, ts, batch_size, time_size)\n",
        "        \n",
        "        # 勾配を求め、パラメータを更新\n",
        "        loss = model.forward(batch_x, batch_t)\n",
        "        model.backward()\n",
        "        params, grads = remove_duplicate(model.params, model.grads)\n",
        "        # 共有された重みを1つに集約\n",
        "        if max_grad is not None:\n",
        "          clip_grads(grads, max_grad)\n",
        "        optimizer.update(params, grads)\n",
        "        total_loss += loss\n",
        "        loss_count += 1\n",
        "        \n",
        "        # パープレキシティの評価\n",
        "        if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
        "          ppl = np.exp(total_loss / loss_count)\n",
        "          elapsed_time = time.time() - start_time\n",
        "          print('| epoch %d | iter %d / %d | time %d[s] | perplexity %.2f' % (self.current_epoch + 1, iters + 1,  max_iters, elapsed_time, ppl))\n",
        "          self.ppl_list.append(float(ppl))\n",
        "          total_loss, loss_count = 0, 0\n",
        "      \n",
        "      self.current_epoch += 1\n",
        "      \n",
        "  def plot(self, ylim=None):\n",
        "    x = numpy.arange(len(self.ppl_list))\n",
        "    if ylim is not None:\n",
        "      plt.ylim(*ylim)\n",
        "    plt.plot(x, self.ppl_list, label='train')\n",
        "    plt.xlabel('iterations (x' + str(self.eval_interval) + ')')\n",
        "    plt.ylabel('perplexity')\n",
        "    plt.show()\n",
        "    \n",
        "def remove_duplicate(params, grads):\n",
        "  '''\n",
        "  パラメータ配列中の重複する重みを一つに集約し、\n",
        "  その重みに対応する勾配を加算する\n",
        "  '''\n",
        "  params, grads = params[:], grads[:] # copy list\n",
        "  \n",
        "  while True:\n",
        "    find_flg = False\n",
        "    L = len(params)\n",
        "    \n",
        "    for i in range(0, L - 1):\n",
        "      for j in range(i + 1, L):\n",
        "        # 重みを共有する場合\n",
        "        if params[i] is params[j]:\n",
        "          grads[i] += grads[j] # 勾配の加算\n",
        "          find_flg = True\n",
        "          params.pop(j)\n",
        "          grads.pop(j)\n",
        "        # 転置行列として重みを共有する場合 (weight tying)\n",
        "        elif params[i].ndim == 2 and params[j].ndim == 2 and params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
        "          grads[i] += grads[j].T\n",
        "          find_flg = True\n",
        "          params.pop(j)\n",
        "          grads.pop(j)\n",
        "          \n",
        "        if find_flg: break\n",
        "      if find_flg: break\n",
        "      \n",
        "    if not find_flg: break\n",
        "    \n",
        "  return params, grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5bvaisfixSxm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dataset/ptb.py\n",
        "\n",
        "# coding: utf-8\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('Use Python3!')\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "url_base = 'https://raw.githubusercontent.com/tomsercu/lstm/master/data/'\n",
        "key_file = {\n",
        "    'train':'ptb.train.txt',\n",
        "    'test':'ptb.test.txt',\n",
        "    'valid':'ptb.valid.txt'\n",
        "}\n",
        "save_file = {\n",
        "    'train':'ptb.train.npy',\n",
        "    'test':'ptb.test.npy',\n",
        "    'valid':'ptb.valid.npy'\n",
        "}\n",
        "vocab_file = 'ptb.vocab.pkl'\n",
        "\n",
        "dataset_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + '/' + file_name\n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print('Downloading ' + file_name + ' ... ')\n",
        "\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "    except urllib.error.URLError:\n",
        "        import ssl\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "        urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "\n",
        "    print('Done')\n",
        "\n",
        "\n",
        "def load_vocab():\n",
        "    vocab_path = dataset_dir + '/' + vocab_file\n",
        "\n",
        "    if os.path.exists(vocab_path):\n",
        "        with open(vocab_path, 'rb') as f:\n",
        "            word_to_id, id_to_word = pickle.load(f)\n",
        "        return word_to_id, id_to_word\n",
        "\n",
        "    word_to_id = {}\n",
        "    id_to_word = {}\n",
        "    data_type = 'train'\n",
        "    file_name = key_file[data_type]\n",
        "    file_path = dataset_dir + '/' + file_name\n",
        "\n",
        "    _download(file_name)\n",
        "\n",
        "    words = open(file_path).read().replace('\\n', '<eos>').strip().split()\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        if word not in word_to_id:\n",
        "            tmp_id = len(word_to_id)\n",
        "            word_to_id[word] = tmp_id\n",
        "            id_to_word[tmp_id] = word\n",
        "\n",
        "    with open(vocab_path, 'wb') as f:\n",
        "        pickle.dump((word_to_id, id_to_word), f)\n",
        "\n",
        "    return word_to_id, id_to_word\n",
        "\n",
        "\n",
        "def load_data(data_type='train'):\n",
        "    '''\n",
        "        :param data_type: データの種類：'train' or 'test' or 'valid (val)'\n",
        "        :return:\n",
        "    '''\n",
        "    if data_type == 'val': data_type = 'valid'\n",
        "    save_path = dataset_dir + '/' + save_file[data_type]\n",
        "\n",
        "    word_to_id, id_to_word = load_vocab()\n",
        "\n",
        "    if os.path.exists(save_path):\n",
        "        corpus = np.load(save_path)\n",
        "        return corpus, word_to_id, id_to_word\n",
        "\n",
        "    file_name = key_file[data_type]\n",
        "    file_path = dataset_dir + '/' + file_name\n",
        "    _download(file_name)\n",
        "\n",
        "    words = open(file_path).read().replace('\\n', '<eos>').strip().split()\n",
        "    corpus = np.array([word_to_id[w] for w in words])\n",
        "\n",
        "    np.save(save_path, corpus)\n",
        "    return corpus, word_to_id, id_to_word\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    for data_type in ('train', 'val', 'test'):\n",
        "        load_data(data_type)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZVp6kPlA1BOO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# common/functions.py\n",
        "\n",
        "# from common.np import *\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x - x.max(axis=1, keepdims=True)\n",
        "        x = np.exp(x)\n",
        "        x /= x.sum(axis=1, keepdims=True)\n",
        "    elif x.ndim == 1:\n",
        "        x = x - np.max(x)\n",
        "        x = np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    # 教師データがone-hot-vectorの場合、正解ラベルのインデックスに変換\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hk3DHqb_043g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# common/layers.py\n",
        "\n",
        "# from common.np import *  # import numpy as np\n",
        "# from common.config import GPU\n",
        "# from common.functions import softmax, cross_entropy_error\n",
        "\n",
        "\n",
        "class MatMul:\n",
        "    def __init__(self, W):\n",
        "        self.params = [W]\n",
        "        self.grads = [np.zeros_like(W)]\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        W, = self.params\n",
        "        out = np.dot(x, W)\n",
        "        self.x = x\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        W, = self.params\n",
        "        dx = np.dot(dout, W.T)\n",
        "        dW = np.dot(self.x.T, dout)\n",
        "        self.grads[0][...] = dW\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        W, b = self.params\n",
        "        out = np.dot(x, W) + b\n",
        "        self.x = x\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        W, b = self.params\n",
        "        dx = np.dot(dout, W.T)\n",
        "        dW = np.dot(self.x.T, dout)\n",
        "        db = np.sum(dout, axis=0)\n",
        "\n",
        "        self.grads[0][...] = dW\n",
        "        self.grads[1][...] = db\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Softmax:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.out = softmax(x)\n",
        "        return self.out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = self.out * dout\n",
        "        sumdx = np.sum(dx, axis=1, keepdims=True)\n",
        "        dx -= self.out * sumdx\n",
        "        return dx\n",
        "\n",
        "\n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.y = None  # softmaxの出力\n",
        "        self.t = None  # 教師ラベル\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "\n",
        "        # 教師ラベルがone-hotベクトルの場合、正解のインデックスに変換\n",
        "        if self.t.size == self.y.size:\n",
        "            self.t = self.t.argmax(axis=1)\n",
        "\n",
        "        loss = cross_entropy_error(self.y, self.t)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "\n",
        "        dx = self.y.copy()\n",
        "        dx[np.arange(batch_size), self.t] -= 1\n",
        "        dx *= dout\n",
        "        dx = dx / batch_size\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = 1 / (1 + np.exp(-x))\n",
        "        self.out = out\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "        return dx\n",
        "\n",
        "\n",
        "class SigmoidWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.loss = None\n",
        "        self.y = None  # sigmoidの出力\n",
        "        self.t = None  # 教師データ\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = 1 / (1 + np.exp(-x))\n",
        "\n",
        "        self.loss = cross_entropy_error(np.c_[1 - self.y, self.y], self.t)\n",
        "\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "\n",
        "        dx = (self.y - self.t) * dout / batch_size\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Dropout:\n",
        "    '''\n",
        "    http://arxiv.org/abs/1207.0580\n",
        "    '''\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.params, self.grads = [], []\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x, train_flg=True):\n",
        "        if train_flg:\n",
        "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
        "            return x * self.mask\n",
        "        else:\n",
        "            return x * (1.0 - self.dropout_ratio)\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask\n",
        "\n",
        "\n",
        "class Embedding:\n",
        "    def __init__(self, W):\n",
        "        self.params = [W]\n",
        "        self.grads = [np.zeros_like(W)]\n",
        "        self.idx = None\n",
        "\n",
        "    def forward(self, idx):\n",
        "        W, = self.params\n",
        "        self.idx = idx\n",
        "        out = W[idx]\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dW, = self.grads\n",
        "        dW[...] = 0\n",
        "        np.add.at(dW, self.idx, dout)\n",
        "        return None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ijkNrPGu0erT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# common/time_layer.py\n",
        "\n",
        "# from common.np import *  # import numpy as np (or import cupy as np)\n",
        "# from common.layers import *\n",
        "# from common.functions import sigmoid\n",
        "\n",
        "\n",
        "class RNN:\n",
        "    def __init__(self, Wx, Wh, b):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.cache = None\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        Wx, Wh, b = self.params\n",
        "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b\n",
        "        h_next = np.tanh(t)\n",
        "\n",
        "        self.cache = (x, h_prev, h_next)\n",
        "        return h_next\n",
        "\n",
        "    def backward(self, dh_next):\n",
        "        Wx, Wh, b = self.params\n",
        "        x, h_prev, h_next = self.cache\n",
        "\n",
        "        dt = dh_next * (1 - h_next ** 2)\n",
        "        db = np.sum(dt, axis=0)\n",
        "        dWh = np.dot(h_prev.T, dt)\n",
        "        dh_prev = np.dot(dt, Wh.T)\n",
        "        dWx = np.dot(x.T, dt)\n",
        "        dx = np.dot(dt, Wx.T)\n",
        "\n",
        "        self.grads[0][...] = dWx\n",
        "        self.grads[1][...] = dWh\n",
        "        self.grads[2][...] = db\n",
        "\n",
        "        return dx, dh_prev\n",
        "\n",
        "\n",
        "class TimeRNN:\n",
        "    def __init__(self, Wx, Wh, b, stateful=False):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.layers = None\n",
        "\n",
        "        self.h, self.dh = None, None\n",
        "        self.stateful = stateful\n",
        "\n",
        "    def forward(self, xs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, D = xs.shape\n",
        "        D, H = Wx.shape\n",
        "\n",
        "        self.layers = []\n",
        "        hs = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "        if not self.stateful or self.h is None:\n",
        "            self.h = np.zeros((N, H), dtype='f')\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = RNN(*self.params)\n",
        "            self.h = layer.forward(xs[:, t, :], self.h)\n",
        "            hs[:, t, :] = self.h\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return hs\n",
        "\n",
        "    def backward(self, dhs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, H = dhs.shape\n",
        "        D, H = Wx.shape\n",
        "\n",
        "        dxs = np.empty((N, T, D), dtype='f')\n",
        "        dh = 0\n",
        "        grads = [0, 0, 0]\n",
        "        for t in reversed(range(T)):\n",
        "            layer = self.layers[t]\n",
        "            dx, dh = layer.backward(dhs[:, t, :] + dh)\n",
        "            dxs[:, t, :] = dx\n",
        "\n",
        "            for i, grad in enumerate(layer.grads):\n",
        "                grads[i] += grad\n",
        "\n",
        "        for i, grad in enumerate(grads):\n",
        "            self.grads[i][...] = grad\n",
        "        self.dh = dh\n",
        "\n",
        "        return dxs\n",
        "\n",
        "    def set_state(self, h):\n",
        "        self.h = h\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.h = None\n",
        "\n",
        "\n",
        "class LSTM:\n",
        "    def __init__(self, Wx, Wh, b):\n",
        "        '''\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        Wx: 入力`x`用の重みパラーメタ（4つ分の重みをまとめる）\n",
        "        Wh: 隠れ状態`h`用の重みパラメータ（4つ分の重みをまとめる）\n",
        "        b: バイアス（4つ分のバイアスをまとめる）\n",
        "        '''\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.cache = None\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, H = h_prev.shape\n",
        "\n",
        "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
        "\n",
        "        f = A[:, :H]\n",
        "        g = A[:, H:2*H]\n",
        "        i = A[:, 2*H:3*H]\n",
        "        o = A[:, 3*H:]\n",
        "\n",
        "        f = sigmoid(f)\n",
        "        g = np.tanh(g)\n",
        "        i = sigmoid(i)\n",
        "        o = sigmoid(o)\n",
        "\n",
        "        c_next = f * c_prev + g * i\n",
        "        h_next = o * np.tanh(c_next)\n",
        "\n",
        "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
        "        return h_next, c_next\n",
        "\n",
        "    def backward(self, dh_next, dc_next):\n",
        "        Wx, Wh, b = self.params\n",
        "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
        "\n",
        "        tanh_c_next = np.tanh(c_next)\n",
        "\n",
        "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
        "\n",
        "        dc_prev = ds * f\n",
        "\n",
        "        di = ds * g\n",
        "        df = ds * c_prev\n",
        "        do = dh_next * tanh_c_next\n",
        "        dg = ds * i\n",
        "\n",
        "        di *= i * (1 - i)\n",
        "        df *= f * (1 - f)\n",
        "        do *= o * (1 - o)\n",
        "        dg *= (1 - g ** 2)\n",
        "\n",
        "        dA = np.hstack((df, dg, di, do))\n",
        "\n",
        "        dWh = np.dot(h_prev.T, dA)\n",
        "        dWx = np.dot(x.T, dA)\n",
        "        db = dA.sum(axis=0)\n",
        "\n",
        "        self.grads[0][...] = dWx\n",
        "        self.grads[1][...] = dWh\n",
        "        self.grads[2][...] = db\n",
        "\n",
        "        dx = np.dot(dA, Wx.T)\n",
        "        dh_prev = np.dot(dA, Wh.T)\n",
        "\n",
        "        return dx, dh_prev, dc_prev\n",
        "\n",
        "\n",
        "class TimeLSTM:\n",
        "    def __init__(self, Wx, Wh, b, stateful=False):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.layers = None\n",
        "\n",
        "        self.h, self.c = None, None\n",
        "        self.dh = None\n",
        "        self.stateful = stateful\n",
        "\n",
        "    def forward(self, xs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, D = xs.shape\n",
        "        H = Wh.shape[0]\n",
        "\n",
        "        self.layers = []\n",
        "        hs = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "        if not self.stateful or self.h is None:\n",
        "            self.h = np.zeros((N, H), dtype='f')\n",
        "        if not self.stateful or self.c is None:\n",
        "            self.c = np.zeros((N, H), dtype='f')\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = LSTM(*self.params)\n",
        "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
        "            hs[:, t, :] = self.h\n",
        "\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return hs\n",
        "\n",
        "    def backward(self, dhs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, H = dhs.shape\n",
        "        D = Wx.shape[0]\n",
        "\n",
        "        dxs = np.empty((N, T, D), dtype='f')\n",
        "        dh, dc = 0, 0\n",
        "\n",
        "        grads = [0, 0, 0]\n",
        "        for t in reversed(range(T)):\n",
        "            layer = self.layers[t]\n",
        "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
        "            dxs[:, t, :] = dx\n",
        "            for i, grad in enumerate(layer.grads):\n",
        "                grads[i] += grad\n",
        "\n",
        "        for i, grad in enumerate(grads):\n",
        "            self.grads[i][...] = grad\n",
        "        self.dh = dh\n",
        "        return dxs\n",
        "\n",
        "    def set_state(self, h, c=None):\n",
        "        self.h, self.c = h, c\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.h, self.c = None, None\n",
        "\n",
        "\n",
        "class TimeEmbedding:\n",
        "    def __init__(self, W):\n",
        "        self.params = [W]\n",
        "        self.grads = [np.zeros_like(W)]\n",
        "        self.layers = None\n",
        "        self.W = W\n",
        "\n",
        "    def forward(self, xs):\n",
        "        N, T = xs.shape\n",
        "        V, D = self.W.shape\n",
        "\n",
        "        out = np.empty((N, T, D), dtype='f')\n",
        "        self.layers = []\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = Embedding(self.W)\n",
        "            out[:, t, :] = layer.forward(xs[:, t])\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        N, T, D = dout.shape\n",
        "\n",
        "        grad = 0\n",
        "        for t in range(T):\n",
        "            layer = self.layers[t]\n",
        "            layer.backward(dout[:, t, :])\n",
        "            grad += layer.grads[0]\n",
        "\n",
        "        self.grads[0][...] = grad\n",
        "        return None\n",
        "\n",
        "\n",
        "class TimeAffine:\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, T, D = x.shape\n",
        "        W, b = self.params\n",
        "\n",
        "        rx = x.reshape(N*T, -1)\n",
        "        out = np.dot(rx, W) + b\n",
        "        self.x = x\n",
        "        return out.reshape(N, T, -1)\n",
        "\n",
        "    def backward(self, dout):\n",
        "        x = self.x\n",
        "        N, T, D = x.shape\n",
        "        W, b = self.params\n",
        "\n",
        "        dout = dout.reshape(N*T, -1)\n",
        "        rx = x.reshape(N*T, -1)\n",
        "\n",
        "        db = np.sum(dout, axis=0)\n",
        "        dW = np.dot(rx.T, dout)\n",
        "        dx = np.dot(dout, W.T)\n",
        "        dx = dx.reshape(*x.shape)\n",
        "\n",
        "        self.grads[0][...] = dW\n",
        "        self.grads[1][...] = db\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class TimeSoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.cache = None\n",
        "        self.ignore_label = -1\n",
        "\n",
        "    def forward(self, xs, ts):\n",
        "        N, T, V = xs.shape\n",
        "\n",
        "        if ts.ndim == 3:  # 教師ラベルがone-hotベクトルの場合\n",
        "            ts = ts.argmax(axis=2)\n",
        "\n",
        "        mask = (ts != self.ignore_label)\n",
        "\n",
        "        # バッチ分と時系列分をまとめる（reshape）\n",
        "        xs = xs.reshape(N * T, V)\n",
        "        ts = ts.reshape(N * T)\n",
        "        mask = mask.reshape(N * T)\n",
        "\n",
        "        ys = softmax(xs)\n",
        "        ls = np.log(ys[np.arange(N * T), ts])\n",
        "        ls *= mask  # ignore_labelに該当するデータは損失を0にする\n",
        "        loss = -np.sum(ls)\n",
        "        loss /= mask.sum()\n",
        "\n",
        "        self.cache = (ts, ys, mask, (N, T, V))\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        ts, ys, mask, (N, T, V) = self.cache\n",
        "\n",
        "        dx = ys\n",
        "        dx[np.arange(N * T), ts] -= 1\n",
        "        dx *= dout\n",
        "        dx /= mask.sum()\n",
        "        dx *= mask[:, np.newaxis]  # ignore_labelに該当するデータは勾配を0にする\n",
        "\n",
        "        dx = dx.reshape((N, T, V))\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class TimeDropout:\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.params, self.grads = [], []\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.mask = None\n",
        "        self.train_flg = True\n",
        "\n",
        "    def forward(self, xs):\n",
        "        if self.train_flg:\n",
        "            flg = np.random.rand(*xs.shape) > self.dropout_ratio\n",
        "            scale = 1 / (1.0 - self.dropout_ratio)\n",
        "            self.mask = flg.astype(np.float32) * scale\n",
        "\n",
        "            return xs * self.mask\n",
        "        else:\n",
        "            return xs\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask\n",
        "\n",
        "\n",
        "class TimeBiLSTM:\n",
        "    def __init__(self, Wx1, Wh1, b1,\n",
        "                 Wx2, Wh2, b2, stateful=False):\n",
        "        self.forward_lstm = TimeLSTM(Wx1, Wh1, b1, stateful)\n",
        "        self.backward_lstm = TimeLSTM(Wx2, Wh2, b2, stateful)\n",
        "        self.params = self.forward_lstm.params + self.backward_lstm.params\n",
        "        self.grads = self.forward_lstm.grads + self.backward_lstm.grads\n",
        "\n",
        "    def forward(self, xs):\n",
        "        o1 = self.forward_lstm.forward(xs)\n",
        "        o2 = self.backward_lstm.forward(xs[:, ::-1])\n",
        "        o2 = o2[:, ::-1]\n",
        "\n",
        "        out = np.concatenate((o1, o2), axis=2)\n",
        "        return out\n",
        "\n",
        "    def backward(self, dhs):\n",
        "        H = dhs.shape[2] // 2\n",
        "        do1 = dhs[:, :, :H]\n",
        "        do2 = dhs[:, :, H:]\n",
        "\n",
        "        dxs1 = self.forward_lstm.backward(do1)\n",
        "        do2 = do2[:, ::-1]\n",
        "        dxs2 = self.backward_lstm.backward(do2)\n",
        "        dxs2 = dxs2[:, ::-1]\n",
        "        dxs = dxs1 + dxs2\n",
        "        return dxs\n",
        "\n",
        "# ====================================================================== #\n",
        "# 以下に示すレイヤは、本書で説明をおこなっていないレイヤの実装もしくは\n",
        "# 処理速度よりも分かりやすさを優先したレイヤの実装です。\n",
        "#\n",
        "# TimeSigmoidWithLoss: 時系列データのためのシグモイド損失レイヤ\n",
        "# GRU: GRUレイヤ\n",
        "# TimeGRU: 時系列データのためのGRUレイヤ\n",
        "# BiTimeLSTM: 双方向LSTMレイヤ\n",
        "# Simple_TimeSoftmaxWithLoss：単純なTimeSoftmaxWithLossレイヤの実装\n",
        "# Simple_TimeAffine: 単純なTimeAffineレイヤの実装\n",
        "# ====================================================================== #\n",
        "\n",
        "\n",
        "class TimeSigmoidWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.xs_shape = None\n",
        "        self.layers = None\n",
        "\n",
        "    def forward(self, xs, ts):\n",
        "        N, T = xs.shape\n",
        "        self.xs_shape = xs.shape\n",
        "\n",
        "        self.layers = []\n",
        "        loss = 0\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = SigmoidWithLoss()\n",
        "            loss += layer.forward(xs[:, t], ts[:, t])\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return loss / T\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        N, T = self.xs_shape\n",
        "        dxs = np.empty(self.xs_shape, dtype='f')\n",
        "\n",
        "        dout *= 1/T\n",
        "        for t in range(T):\n",
        "            layer = self.layers[t]\n",
        "            dxs[:, t] = layer.backward(dout)\n",
        "\n",
        "        return dxs\n",
        "\n",
        "\n",
        "class GRU:\n",
        "    def __init__(self, Wx, Wh):\n",
        "        '''\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        Wx: 入力`x`用の重みパラーメタ（3つ分の重みをまとめる）\n",
        "        Wh: 隠れ状態`h`用の重みパラメータ（3つ分の重みをまとめる）\n",
        "        '''\n",
        "        self.Wx, self.Wh = Wx, Wh\n",
        "        self.dWx, self.dWh = None, None\n",
        "        self.cache = None\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        H, H3 = self.Wh.shape\n",
        "        Wxz, Wxr, Wx = self.Wx[:, :H], self.Wx[:, H:2 * H], self.Wx[:, 2 * H:]\n",
        "        Whz, Whr, Wh = self.Wh[:, :H], self.Wh[:, H:2 * H], self.Wh[:, 2 * H:]\n",
        "\n",
        "        z = sigmoid(np.dot(x, Wxz) + np.dot(h_prev, Whz))\n",
        "        r = sigmoid(np.dot(x, Wxr) + np.dot(h_prev, Whr))\n",
        "        h_hat = np.tanh(np.dot(x, Wx) + np.dot(r*h_prev, Wh))\n",
        "        h_next = (1-z) * h_prev + z * h_hat\n",
        "\n",
        "        self.cache = (x, h_prev, z, r, h_hat)\n",
        "\n",
        "        return h_next\n",
        "\n",
        "    def backward(self, dh_next):\n",
        "        H, H3 = self.Wh.shape\n",
        "        Wxz, Wxr, Wx = self.Wx[:, :H], self.Wx[:, H:2 * H], self.Wx[:, 2 * H:]\n",
        "        Whz, Whr, Wh = self.Wh[:, :H], self.Wh[:, H:2 * H], self.Wh[:, 2 * H:]\n",
        "        x, h_prev, z, r, h_hat = self.cache\n",
        "\n",
        "        dh_hat =dh_next * z\n",
        "        dh_prev = dh_next * (1-z)\n",
        "\n",
        "        # tanh\n",
        "        dt = dh_hat * (1 - h_hat ** 2)\n",
        "        dWh = np.dot((r * h_prev).T, dt)\n",
        "        dhr = np.dot(dt, Wh.T)\n",
        "        dWx = np.dot(x.T, dt)\n",
        "        dx = np.dot(dt, Wx.T)\n",
        "        dh_prev += r * dhr\n",
        "\n",
        "        # update gate(z)\n",
        "        dz = dh_next * h_hat - dh_next * h_prev\n",
        "        dt = dz * z * (1-z)\n",
        "        dWhz = np.dot(h_prev.T, dt)\n",
        "        dh_prev += np.dot(dt, Whz.T)\n",
        "        dWxz = np.dot(x.T, dt)\n",
        "        dx += np.dot(dt, Wxz.T)\n",
        "\n",
        "        # rest gate(r)\n",
        "        dr = dhr * h_prev\n",
        "        dt = dr * r * (1-r)\n",
        "        dWhr = np.dot(h_prev.T, dt)\n",
        "        dh_prev += np.dot(dt, Whr.T)\n",
        "        dWxr = np.dot(x.T, dt)\n",
        "        dx += np.dot(dt, Wxr.T)\n",
        "\n",
        "        self.dWx = np.hstack((dWxz, dWxr, dWx))\n",
        "        self.dWh = np.hstack((dWhz, dWhr, dWh))\n",
        "\n",
        "        return dx, dh_prev\n",
        "\n",
        "\n",
        "class TimeGRU:\n",
        "    def __init__(self, Wx, Wh, stateful=False):\n",
        "        self.Wx, self.Wh = Wx, Wh\n",
        "        selfdWx, self.dWh = None, None\n",
        "        self.layers = None\n",
        "        self.h, self.dh = None, None\n",
        "        self.stateful = stateful\n",
        "\n",
        "    def forward(self, xs):\n",
        "        N, T, D = xs.shape\n",
        "        H, H3 = self.Wh.shape\n",
        "\n",
        "        self.layers = []\n",
        "        hs = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "        if not self.stateful or self.h is None:\n",
        "            self.h = np.zeros((N, H), dtype='f')\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = GRU(self.Wx, self.Wh)\n",
        "            self.h = layer.forward(xs[:, t, :], self.h)\n",
        "            hs[:, t, :] = self.h\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return hs\n",
        "\n",
        "    def backward(self, dhs):\n",
        "        N, T, H = dhs.shape\n",
        "        D = self.Wx.shape[0]\n",
        "\n",
        "        dxs = np.empty((N, T, D), dtype='f')\n",
        "        self.dWx, self.dWh = 0, 0\n",
        "\n",
        "        dh = 0\n",
        "        for t in reversed(range(T)):\n",
        "            layer = self.layers[t]\n",
        "            dx, dh = layer.backward(dhs[:, t, :] + dh)\n",
        "\n",
        "            dxs[:, t, :] = dx\n",
        "            self.dWx += layer.dWx\n",
        "            self.dWh += layer.dWh\n",
        "\n",
        "        self.dh = dh\n",
        "        return dxs\n",
        "\n",
        "    def set_state(self, h):\n",
        "        self.h = h\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.h = None\n",
        "\n",
        "\n",
        "class Simple_TimeSoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.cache = None\n",
        "\n",
        "    def forward(self, xs, ts):\n",
        "        N, T, V = xs.shape\n",
        "        layers = []\n",
        "        loss = 0\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = SoftmaxWithLoss()\n",
        "            loss += layer.forward(xs[:, t, :], ts[:, t])\n",
        "            layers.append(layer)\n",
        "        loss /= T\n",
        "\n",
        "        self.cache = (layers, xs)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        layers, xs = self.cache\n",
        "        N, T, V = xs.shape\n",
        "        dxs = np.empty(xs.shape, dtype='f')\n",
        "\n",
        "        dout *= 1/T\n",
        "        for t in range(T):\n",
        "            layer = layers[t]\n",
        "            dxs[:, t, :] = layer.backward(dout)\n",
        "\n",
        "        return dxs\n",
        "\n",
        "\n",
        "class Simple_TimeAffine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W, self.b = W, b\n",
        "        self.dW, self.db = None, None\n",
        "        self.layers = None\n",
        "\n",
        "    def forward(self, xs):\n",
        "        N, T, D = xs.shape\n",
        "        D, M = self.W.shape\n",
        "\n",
        "        self.layers = []\n",
        "        out = np.empty((N, T, M), dtype='f')\n",
        "        for t in range(T):\n",
        "            layer = Affine(self.W, self.b)\n",
        "            out[:, t, :] = layer.forward(xs[:, t, :])\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        N, T, M = dout.shape\n",
        "        D, M = self.W.shape\n",
        "\n",
        "        dxs = np.empty((N, T, D), dtype='f')\n",
        "        self.dW, self.db = 0, 0\n",
        "        for t in range(T):\n",
        "            layer = self.layers[t]\n",
        "            dxs[:, t, :] = layer.backward(dout[:, t, :])\n",
        "\n",
        "            self.dW += layer.dW\n",
        "            self.db += layer.db\n",
        "\n",
        "        return dxs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Vl-dkWM1hSz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# common/base_model.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "# from common.np import *\n",
        "# from common.util import to_gpu, to_cpu\n",
        "\n",
        "\n",
        "class BaseModel:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = None, None\n",
        "\n",
        "    def forward(self, *args):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, *args):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def save_params(self, file_name=None):\n",
        "        if file_name is None:\n",
        "            file_name = self.__class__.__name__ + '.pkl'\n",
        "\n",
        "        params = [p.astype(np.float16) for p in self.params]\n",
        "        if GPU:\n",
        "            params = [to_cpu(p) for p in params]\n",
        "\n",
        "        with open(file_name, 'wb') as f:\n",
        "            pickle.dump(params, f)\n",
        "\n",
        "    def load_params(self, file_name=None):\n",
        "        if file_name is None:\n",
        "            file_name = self.__class__.__name__ + '.pkl'\n",
        "\n",
        "        if '/' in file_name:\n",
        "            file_name = file_name.replace('/', os.sep)\n",
        "\n",
        "        if not os.path.exists(file_name):\n",
        "            raise IOError('No file: ' + file_name)\n",
        "\n",
        "        with open(file_name, 'rb') as f:\n",
        "            params = pickle.load(f)\n",
        "\n",
        "        params = [p.astype('f') for p in params]\n",
        "        if GPU:\n",
        "            params = [to_gpu(p) for p in params]\n",
        "\n",
        "        for i, param in enumerate(self.params):\n",
        "            param[...] = params[i]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EjULMqlSxgXK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ch06/rnnlm.py\n",
        "\n",
        "# from common.time_layer import *\n",
        "# from common.base_model import BaseModel\n",
        "\n",
        "class Rnnlm(BaseModel):\n",
        "  def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
        "    V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "    rn = np.random.randn\n",
        "    \n",
        "    # 重みの初期化\n",
        "    embed_W = (rn(V, D) / 100).astype('f')\n",
        "    lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "    lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "    lstm_b = np.zeros(4 * H).astype('f')\n",
        "    affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
        "    affine_b = np.zeros(V).astype('f')\n",
        "    \n",
        "    # レイヤの生成\n",
        "    self.layers = [\n",
        "        TimeEmbedding(embed_W),\n",
        "        TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
        "        TimeAffine(affine_W, affine_b)\n",
        "    ]\n",
        "    self.loss_layer = TimeSoftmaxWithLoss()\n",
        "    self.lstm_layer = self.layers[1]\n",
        "    \n",
        "    # すべての重みと勾配をリストにまとめる\n",
        "    self.params, self.grads = [], []\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "    \n",
        "  def predict(self, xs):\n",
        "    for layer in self.layers:\n",
        "      xs = layer.forward(xs)\n",
        "    return  xs\n",
        "  \n",
        "  def forward(self, xs, ts):\n",
        "    score = self.predict(xs)\n",
        "    loss = self.loss_layer.forward(score, ts)\n",
        "    return loss\n",
        "  \n",
        "  def backward(self, dout=1):\n",
        "    dout = self.loss_layer.backward(dout)\n",
        "    for layer in reversed(self.layers):\n",
        "      dout = layer.backward(dout)\n",
        "    return dout\n",
        "  \n",
        "  def reset_state(self):\n",
        "    self.lstm_layer.reset_state()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtNivm_l2zsD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ch06/train_rnnlm.py\n",
        "\n",
        "# from common.optimizer import SGD\n",
        "# from common.trainer import RnnlmTrainer\n",
        "# from common.util import eval_preplexity\n",
        "# from dataset import ptb\n",
        "# from rnnlm import Rnnlm\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "batch_size = 20\n",
        "wordvec_size = 100\n",
        "hidden_size = 100 # RNNの隠れ状態ベクトルの要素数\n",
        "time_size = 35 # RNNを展開するサイズ\n",
        "lr = 20.0\n",
        "max_epoch = 4\n",
        "max_grad = 0.25\n",
        "\n",
        "# 学習データの読み込み\n",
        "corpus, word_to_id, id_to_word = load_data('train')\n",
        "corpus_text, _, _ = load_data('test')\n",
        "vocab_size = len(word_to_id)\n",
        "xs = corpus[:-1]\n",
        "ts = corpus[1:]\n",
        "\n",
        "# モデルの生成\n",
        "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
        "optimizer = SGD(lr)\n",
        "trainer = RnnlmTrainer(model, optimizer)\n",
        "\n",
        "# 勾配クリッピングを適応して学習\n",
        "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval=20)\n",
        "trainer.plot(ylim=(0, 500))\n",
        "\n",
        "# テストデータで評価\n",
        "model.reset_state()\n",
        "ppl_test = eval_perplexity(model, corpus_test)\n",
        "print('test perplexity: ', ppl_test)\n",
        "\n",
        "# パラメータの保存\n",
        "model.save_params()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2vLPntooKUpO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## LSTMの勾配の流れ\n",
        "LSTMで、記憶セルcの順伝播では、+とxノードだけを通り、行列の積ではなく、アダマール積(各要素ごとの積)が行われているので、劣化が起こりにくくなっている\n",
        "\n",
        "また、積の計算を行っているforgetゲートでは、忘れてはいけないと導いた要素に対して、劣化することなく過去方向へ伝わるので、勾配消失を起こさず伝播することが期待できる"
      ]
    },
    {
      "metadata": {
        "id": "PPsYaihgLcfx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "cbt0ZHrz665T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## RNNLMの改善\n",
        "- 多層化\n",
        "LSTMレイヤを重ねることで、精度向上が期待できる\n",
        "- Dropoutによる過学習の抑制\n",
        "- 重み共有　(EmbeddingレイヤとAffineレイヤの重みを結びつける(共有する))"
      ]
    },
    {
      "metadata": {
        "id": "M_X-1sqC84m6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 正則化\n",
        "モデルの複雑さにペナルティーを与えること\n",
        "\n",
        "過学習を抑制する目的で行う\n",
        "\n",
        "e.x)\n",
        "- 重みが大きくなりすぎることにペナルティーを課す(L2正則化)\n",
        "- ニューロンのいくつかをランダムに無視して学習を行う(Dropout)"
      ]
    },
    {
      "metadata": {
        "id": "aQckdCqD-VHi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "RNNLMでは、時間方向(左右)ではなく、深さ方向(上下)にDropoutを適応している\n",
        "\n",
        "ノイズの蓄積を考慮したため。\n",
        "\n",
        "しかし、変分Dropoutでは、時間方向への適応に成功している"
      ]
    },
    {
      "metadata": {
        "id": "itiwA8p_Nedv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 重み共有\n",
        "Embeddingレイヤの重みとAffineレイヤの重みを結びつける(共有する)テクニック\n",
        "\n",
        "学習するパラメータを削減でき、\n",
        "精度も向上する\n",
        "\n",
        "なぜ？-> 論文参照\n"
      ]
    }
  ]
}