{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3章.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utree/deeplearning2_colab_log/blob/master/3%E7%AB%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dRtOsVYwue4B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 単語の分散表現 〜推論ベースの手法word2vec〜\n",
        "カウントベースの手法では、周囲の単語の頻度によって、共起行列を作り、その行列に対して、SVDを適応することで、密なベクトル単語の分散表現を獲得しました。\n",
        "\n",
        "しかし、カウントベースの手法には問題点があり、大規模なコーパスを扱う場合、巨大な行列を作ることになります。しかし、巨大な行列に対して、SVDを行うことは現実的ではありません。"
      ]
    },
    {
      "metadata": {
        "id": "MPWf3XOZvuMq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 推論ベースの手法\n",
        "\n",
        "コンテキストが与えられたときに、どのような単語が出現するのかを推論する手法\n",
        "\n",
        "推論問題を繰り返し解き、出現パーターンを学習する\n",
        "\n",
        "モデルにコンテキストを入力として与えると、モデルは各単語の出現確率を出力する"
      ]
    },
    {
      "metadata": {
        "id": "NiQyWWY1SXQ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "one-hot表現で単語をベクトル表現で表すと\n",
        "\n",
        "ニューラルネットワークを構成する様々な「レイヤ」によって処理することができる"
      ]
    },
    {
      "metadata": {
        "id": "mpmxk9oIttvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ff015a04-5f92-4478-9647-f6e101fd02fd"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "c = np.array([[1, 0, 0, 0, 0, 0, 0]]) # 入力\n",
        "W = np.random.randn(7, 3) # 重み\n",
        "# バイアスを用いいない全結合層のニューラルネット = 「行列の積」\n",
        "h = np.dot(c, W) # 中間ノード\n",
        "print(h)\n",
        "\n",
        "# one-hotベクトルの積では、該当する重みの行ベクトルを抜き出すことに相当する"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.31117849 -1.89414643 -1.46252998]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p5u18dAgZ_Na",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SLNz2oxLY4aF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MatMul:\n",
        "  '''\n",
        "    MatMul(行列の積)レイヤ\n",
        "  '''\n",
        "  def __init__(self, W):\n",
        "    self.params = [W]\n",
        "    self.grads = [np.zeros_like(W)]\n",
        "    self.x = None\n",
        "    \n",
        "  def forward(self, x):\n",
        "    W, = self.params\n",
        "    out = np.dot(x, W)\n",
        "    self.x = x\n",
        "    return out\n",
        "  \n",
        "  def backward(self, dout):\n",
        "    W, = self.params\n",
        "    dx = np.dot(dout, W.T)\n",
        "    dW = np.dot(self.x.T, dout)\n",
        "    self.grads[0][...] = dW\n",
        "    return dx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XyHZyMLUaCvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72530fd7-132d-4f78-e4fd-aef8484b2c16"
      },
      "cell_type": "code",
      "source": [
        "# MatMulレイヤで実装\n",
        "c = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
        "W = np.random.randn(7, 3)\n",
        "layer = MatMul(W)\n",
        "h = layer.forward(c)\n",
        "print(h)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.33967714  0.1365977  -1.12722566]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1inrCi6bjfri",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "word2vecでは、ニューラルネットワークのモデルにcontinuous bag-of-words(CBOW)を用いる"
      ]
    },
    {
      "metadata": {
        "id": "jtbwT5-6yGCF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CBOWのデータ処理構造\n",
        "\n",
        "入力層でone-hot表現のベクトル受け取り、中間層で全結合による変換後の値の平均値を出し、出力層で、各単語のスコアを算出する\n",
        "\n",
        "そのスコアにSoftmax関数を適応すると、確率が得られる\n",
        "\n",
        "そして、この確率には、単語の意味もエンコードされている"
      ]
    },
    {
      "metadata": {
        "id": "hVV8Fo7y5Wbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4522ddef-0874-4ae3-b07e-b475accd9131"
      },
      "cell_type": "code",
      "source": [
        "# サンプルのコンテキストデータ\n",
        "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
        "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])\n",
        "\n",
        "# 重みの初期化\n",
        "W_in = np.random.randn(7, 3)\n",
        "W_out = np.random.randn(3, 7)\n",
        "\n",
        "# レイヤの生成\n",
        "in_layer0 = MatMul(W_in)\n",
        "in_layer1 = MatMul(W_in)\n",
        "out_layer = MatMul(W_out)\n",
        "\n",
        "# 順伝播\n",
        "h0 = in_layer0.forward(c0)\n",
        "h1 = in_layer1.forward(c1)\n",
        "h = 0.5 * (h0 + h1)\n",
        "s = out_layer.forward(h)\n",
        "\n",
        "print(s)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.23199029  0.48978974 -0.8598195   0.47971249  1.20140243 -0.8945531\n",
            "   0.244637  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}