{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2章.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utree/deeplearning2_colab_log/blob/master/2%E7%AB%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8ugvXt33Hlep",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "単語の意味"
      ]
    },
    {
      "metadata": {
        "id": "IZGKNEQDHusV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "コンピュータに単語の意味を理解させるには\n",
        "- シソーラスによる手法\n",
        "- カウントベースの手法\n",
        "- 推論ベースの方法(word2vec)"
      ]
    },
    {
      "metadata": {
        "id": "ZRntH4iiILWR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# シソーラス\n",
        "シソーラスとは、類語辞典で、「同じ意味の単語(同義語)」や「似た意味の単語(類義語)」が同じグループに存在する\n",
        "\n",
        "シソーラスでは、「上位と下位」「全体と部分」などの細かい関係性が定義されている場合があり、単語間のつながりである「単語ネットワーク」を利用することで、コンピュータに単語の意味を授けることができる"
      ]
    },
    {
      "metadata": {
        "id": "xz6shgFQJQco",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "自然言語処理の分野において、最も有名なシソーラスは**WordNet**で、類義語の取得、類似度の算出ができる。"
      ]
    },
    {
      "metadata": {
        "id": "BpNCMWbtNOan",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "シソーラスの問題点\n",
        "- 時代の変化に対応するのが、困難\n",
        "- 人の作業コストが高い\n",
        "- 単語の細かなニュアンスを表現できない"
      ]
    },
    {
      "metadata": {
        "id": "6c-6E5u5Nu1t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# カウントベースによる手法\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2b6VzjrlN46u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# コーパス\n",
        "コーパスとは、目的を持って収集された、大量のテキストデータ"
      ]
    },
    {
      "metadata": {
        "id": "YOlcmt14HuXP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text = 'You say goodbye and I say hello.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OubepJ-sHjBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "83c43abd-e190-4202-b4b1-e195f8fbfee8"
      },
      "cell_type": "code",
      "source": [
        "text = text.lower() # 小文字に変換\n",
        "text = text.replace('.', ' .') # .を .に変換\n",
        "text"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you say goodbye and i say hello .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "vxpUtVjsOhg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9306fb7c-e732-4f14-c5fa-15cd5d78c649"
      },
      "cell_type": "code",
      "source": [
        "words = text.split(' ') # スペースを区切り文字として分割\n",
        "words # 文を単語のリストとして、保存"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "z1IeFeUtO2yc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_to_id = {}\n",
        "id_to_word = {}\n",
        "\n",
        "# 単語にidを振って、IDのリストとして利用できるように変更を加える\n",
        "for word in words:\n",
        "  if word not in  word_to_id:\n",
        "    new_id = len(word_to_id)\n",
        "    word_to_id[word] = new_id\n",
        "    id_to_word[new_id] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSIUQuFlPXwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20423fc4-06ab-461e-a7f9-bbdec6f7fd97"
      },
      "cell_type": "code",
      "source": [
        "id_to_word # idから単語を検索できる"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "XIpTl6gPPbGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba954a14-b5d3-47ab-d0c9-b4cd8f7cd1ce"
      },
      "cell_type": "code",
      "source": [
        "word_to_id # 単語からidを検索できる"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 6, 'and': 3, 'goodbye': 2, 'hello': 5, 'i': 4, 'say': 1, 'you': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "XZBl4d8bPq7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9807f3f8-d4ca-48b4-bf1f-3b30e5b90acd"
      },
      "cell_type": "code",
      "source": [
        "id_to_word[1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'say'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "6eqcxsv0Ps-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7712dd6a-eea2-4660-bbaf-5467e4a1d177"
      },
      "cell_type": "code",
      "source": [
        "word_to_id['hello']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "AOvQ3CEgPz5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2bec0157-342d-4579-92fa-7a1445ed5eba"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# words: 単語のリストを word_to_id: 単語IDのリストに変換\n",
        "corpus = [word_to_id[w] for w in words]\n",
        "# word_to_id: 単語IDのリストを corpus: numpy配列に変換\n",
        "corpus = np.array(corpus)\n",
        "corpus"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 1, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "7ef_tKsNQfB-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  '''\n",
        "    文字列を前処理して、単語リストを出力する\n",
        "  '''\n",
        "  text = text.lower()\n",
        "  text = text.replace('.', ' .')\n",
        "  words = text.split(' ')\n",
        "  \n",
        "  word_to_id = {}\n",
        "  id_to_word = {}\n",
        "  for word in words:\n",
        "    if word not in word_to_id:\n",
        "      new_id = len(word_to_id)\n",
        "      word_to_id[word] = new_id\n",
        "      id_to_word[new_id] = word\n",
        "  \n",
        "  corpus = np.array([word_to_id[w] for w in words])\n",
        "  \n",
        "  return corpus, word_to_id, id_to_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ckjml2sxRnRQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 単語の分散表現\n",
        "\n",
        "単語の意味をベクトル表記したもの"
      ]
    },
    {
      "metadata": {
        "id": "8W1qwDqfRxQb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 分布仮説\n",
        "単語の意味は周囲の単語によって形成される"
      ]
    },
    {
      "metadata": {
        "id": "f434Ghy0R9_m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## コンテキスト\n",
        "\n",
        "周囲に存在する単語"
      ]
    },
    {
      "metadata": {
        "id": "3GJpc9JsSJRp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 共起行列\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JnfB__BURPf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fccec9cc-34d9-414a-a497-dbb0898f1bcf"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "print(corpus)\n",
        "\n",
        "print(id_to_word)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 1 5 6]\n",
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FQd1CufpSmX2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 共起行列\n",
        "C = np.array([\n",
        "    [0, 1, 0, 0, 0, 0, 0],\n",
        "    [1, 0, 1, 0, 1, 1, 0],\n",
        "    [0, 1, 0, 1, 0, 0, 0],\n",
        "    [0, 0, 1, 0, 1, 0, 0],\n",
        "    [0, 1, 0, 1, 0, 0, 0],\n",
        "    [0, 1, 0, 0, 0, 0, 1],\n",
        "    [0, 0, 0, 0, 0, 1, 0],\n",
        "], dtype=np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8P-k_lUlS_Wi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59222397-3ce1-4bcf-e281-46246610ee13"
      },
      "cell_type": "code",
      "source": [
        "print(C[0]) # 単語IDが0のベクトル"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "caRjKMJrTEs9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cb979e7d-651e-4015-c1de-69d2495fcab1"
      },
      "cell_type": "code",
      "source": [
        "print(C[4]) # 単語IDが4のベクトル"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 1 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m0XTMGGOTJjQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e8e8abee-ad25-4159-c55c-69c170bed861"
      },
      "cell_type": "code",
      "source": [
        "print(C[word_to_id['goodbye']]) # \"goodbye\"のベクトル"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 1 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b3HX9w37TTOV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
        "  '''\n",
        "    コーパスから共起行列をつくる関数\n",
        "  '''\n",
        "  \n",
        "  corpus_size = len(corpus)\n",
        "  co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
        "  \n",
        "  for idx, word_id in enumerate(corpus):\n",
        "    for i in range(1, window_size + 1):\n",
        "      left_idx = idx - i\n",
        "      right_idx = idx + i\n",
        "      \n",
        "      if left_idx >= 0:\n",
        "        left_word_id = corpus[left_idx]\n",
        "        co_matrix[word_id, left_word_id] += 1\n",
        "      \n",
        "      if right_idx < corpus_size:\n",
        "        right_word_id = corpus[right_idx]\n",
        "        co_matrix[word_id, right_word_id] += 1\n",
        "  \n",
        "  return co_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V3Wima2hUhvV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## コサイン類似度\n",
        "\n",
        "2つのベクトルがあるとき、どれだけ同じ方向を見いているかを1から-1の間の数字で表す\n",
        "\n",
        "全く同じ時、コサイン類似度は1\n",
        "\n",
        "完全に逆向きだと、-1になる"
      ]
    },
    {
      "metadata": {
        "id": "KrlD6icMUzrQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cos_similarity(x, y):\n",
        "  '''\n",
        "    コサイン類似度を算出する\n",
        "  '''\n",
        "  nx = x / np.sqrt(np.sum(x**2)) # xの正規化\n",
        "  ny = y / np.sqrt(np.sum(y**2)) # yの正規化\n",
        "  return np.dot(nx, ny)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PO0LvrsoVI-M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "0ベクトルが引数に入ると0除算が発生してしまうので、esp=1e-8を加算して、対処"
      ]
    },
    {
      "metadata": {
        "id": "QszhhPU2VUtg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cos_similarity(x, y, eps=1e-8):\n",
        "  '''\n",
        "    コサイン類似度を算出する(改良版)\n",
        "  '''\n",
        "  nx = x / (np.sqrt(np.sum(x**2)) + eps)\n",
        "  ny = y / (np.sqrt(np.sum(y**2)) + eps)\n",
        "  return np.dot(nx, ny)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rp27DrtaVrIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15c62190-94c2-47b6-d53b-3c5fafe0c420"
      },
      "cell_type": "code",
      "source": [
        "text  = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "\n",
        "c0 = C[word_to_id['you']] # \"you\"の単語ベクトル\n",
        "c1 = C[word_to_id['i']] # \"i\"の単語ベクトル\n",
        "print(cos_similarity(c0, c1))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7071067691154799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YxoCsH-2WTVs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 類似単語のランキングを表示\n",
        "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
        "  '''\n",
        "    引数\n",
        "    \n",
        "    query: クエリ(単語)\n",
        "    word_to_id: 単語から単語IDへのディクショナリ\n",
        "    id_to_word: 単語IDから単語へのディクショナリ\n",
        "    word_matrix: 単語ベクトルをまとめた行列\n",
        "    top: 上位何位まで表示するか\n",
        "  '''\n",
        "  \n",
        "  # クエリを取り出す\n",
        "  if query not in word_to_id:\n",
        "    print('%s is not found' % query)\n",
        "    return\n",
        "  \n",
        "  print('\\n[query] ' + query)\n",
        "  query_id = word_to_id[query]\n",
        "  query_vec = word_matrix[query_id]\n",
        "  \n",
        "  # コサイン類似度の算出\n",
        "  vocab_size = len(id_to_word)\n",
        "  similarity = np.zeros(vocab_size)\n",
        "  for i in range(vocab_size):\n",
        "    similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
        "    \n",
        "  # コサイン類似度の結果からその値を高い順に出力\n",
        "  count = 0\n",
        "  for i in (-1 * similarity).argsort(): # argsort関数で、インデックスを要素の小さい順にソートし、インデックス番号を返す\n",
        "    if id_to_word[i] == query:\n",
        "      continue\n",
        "    print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
        "    \n",
        "    count += 1\n",
        "    if count >= top:\n",
        "      return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WiZ0aA57YHyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e894f8e2-ce20-4803-f808-8b19bdaadd6b"
      },
      "cell_type": "code",
      "source": [
        "# argsort\n",
        "\n",
        "x = np.array([100, -20, 2])\n",
        "x.argsort()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "MSCTmHWNYbWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54269c0a-449b-41f1-ce2a-7b93e22930b2"
      },
      "cell_type": "code",
      "source": [
        "(-x).argsort()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "c_-IqW-kYhKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "1e8d5a81-91c3-481c-cc6c-f74a62b08ba3"
      },
      "cell_type": "code",
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "\n",
        "most_similar('you', word_to_id, id_to_word, C, top=5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[query] you\n",
            " goodbye: 0.7071067691154799\n",
            " i: 0.7071067691154799\n",
            " hello: 0.7071067691154799\n",
            " say: 0.0\n",
            " and: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mt47WPdVY_91",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 相互情報量(PMI)\n",
        "\n",
        "単語間の共起を考えるときに、単なる出現回数を数えると\"the\"のような高頻度単語に強い関連性が現れてしまう。\n",
        "\n",
        "そこで、単独での出現回数と、共起回数の確率を考慮したPMIという指標を用いる"
      ]
    },
    {
      "metadata": {
        "id": "MQtpau7fab22",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "共起回数０の場合-∞になってしまうことを考慮して、実践上は**正の相互情報量(Positive PMI)**を用いる"
      ]
    },
    {
      "metadata": {
        "id": "e8v_8bUDayDK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ppmi(C, verbose=False, eps=1e-8):\n",
        "  '''\n",
        "    共起行列をPPMI行列に変換する関数\n",
        "  '''\n",
        "  M = np.zeros_like(C, dtype=np.float32)\n",
        "  N = np.sum(C)\n",
        "  S = np.sum(C, axis=0)\n",
        "  total = C.shape[0] * C.shape[1]\n",
        "  cnt = 0\n",
        "  \n",
        "  for i in range(C.shape[0]):\n",
        "    for j in range(C.shape[1]):\n",
        "      pmi = np.log2(C[i, j]*N / (S[j]*S[i]) + eps)\n",
        "      M[i, j] = max(0, pmi)\n",
        "      \n",
        "      if verbose:\n",
        "        cnt += 1\n",
        "        if cnt % (total//100) == 0:\n",
        "          print('%.1f%% done' % (100*cnt/total))\n",
        "  return M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M-hmlEfCbl9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "86fb04fe-4d41-4b7c-9a8e-8cb6197fbe50"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "W = ppmi(C)\n",
        "\n",
        "np.set_printoptions(precision=3) # 有効桁3桁で表示\n",
        "print('covariance matrix')\n",
        "print(C)\n",
        "print('-'*50)\n",
        "print('PPMI')\n",
        "print(W)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "covariance matrix\n",
            "[[0 1 0 0 0 0 0]\n",
            " [1 0 1 0 1 1 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0]]\n",
            "--------------------------------------------------\n",
            "PPMI\n",
            "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
            " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.807 0.    0.    0.    0.    2.807]\n",
            " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vjUdQnFJeZnW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "PPMI行列は、単語数が増えると、ベクトルの次元数も増える。\n",
        "\n",
        "行列の中身を見てみると0が多い。つまり、重要でない要素が多い\n",
        "\n",
        "このようなベクトルは、ノイズに弱い。\n",
        "\n",
        "\n",
        "ここで用いられる対処法が、ベクトルの次元削減(dimensionality reduction)"
      ]
    },
    {
      "metadata": {
        "id": "XJWiz6ghe4ZD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次元削減を行う方法の一つとして、特異値分解(Singular Value Decomposition: SVD)がある。\n",
        "\n",
        "SVDでは、任意の行列XをUSVの３つの行列に分解する\n",
        "\n",
        "また、UとVは直交行列で、列ベクトルはお互いに直行する\n",
        "\n",
        "Sは対角行列で、対角成分以外はすべて0の行列"
      ]
    },
    {
      "metadata": {
        "id": "CYc-jrzsfixE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 直交行列\n",
        "転置行列と逆行列が等しくなる正方行列"
      ]
    },
    {
      "metadata": {
        "id": "cldB1kJwfl0_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 転置行列\n",
        "\n",
        "![転置行列](https://techblog.nhn-techorus.com/wp-content/uploads/2015/12/matrix3_6.1.png)"
      ]
    },
    {
      "metadata": {
        "id": "ZMGLXeicfnx6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 逆行列\n",
        "\n",
        "![逆行列](https://atarimae.biz/wp-content/uploads/2018/06/inverse-2-2.png)"
      ]
    },
    {
      "metadata": {
        "id": "MOBfWk5hjVlt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 対角行列\n",
        "\n",
        "対角成分以外はすべて0の行列"
      ]
    },
    {
      "metadata": {
        "id": "Vlg-Za7lfpjK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(id_to_word)\n",
        "C = create_co_matrix(corpus, vocab_size, window_size=1)\n",
        "W = ppmi(C)\n",
        "\n",
        "# SVD\n",
        "U, S, V = np.linalg.svd(W) # linalg(linear algebra: 線形代数)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oNWiIMXDk3t1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5046a56-fcc4-43fa-9bc2-16105ade0679"
      },
      "cell_type": "code",
      "source": [
        "print(C[0]) # 共起行列"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P-CFYE4Hk7Fd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e80d07fb-8c45-49ef-b479-d340a6173aaa"
      },
      "cell_type": "code",
      "source": [
        "print(W[0]) # PPMI行列"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.    1.807 0.    0.    0.    0.    0.   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eEH0OF7Jk-3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bc7b9555-9c04-4598-ab95-882326d9a32e"
      },
      "cell_type": "code",
      "source": [
        "print(U[0]) # SVD"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3.409e-01  0.000e+00 -1.205e-01 -3.886e-16 -9.323e-01 -1.110e-16\n",
            " -2.426e-17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rO0kvzrImjpJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "共起行列: C[]がPPMI行列W[]に変換され、SVDによって、密なベクトルU[]に変換されている。"
      ]
    },
    {
      "metadata": {
        "id": "vuG6FHT4m2Mu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c43da9dc-7d5d-465f-feb7-9cff49a34405"
      },
      "cell_type": "code",
      "source": [
        "print(U[0, :2])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.341 0.   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9UkYQi6xm5V7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "この密なベクトルを次元削減するには、単に、先頭の２つの要素を取り出す"
      ]
    },
    {
      "metadata": {
        "id": "Ovb9Xv45lVXJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "e786c1fc-2bdd-4a73-d338-e4642b1c445c"
      },
      "cell_type": "code",
      "source": [
        "# 2次元のベクトルで表し、グラフにプロット\n",
        "for word, word_id in word_to_id.items():\n",
        "  plt.annotate(word, (U[word_id, 0], U[word_id, 1])) # annotate(word, x, y)でx, y地点にwordを描画\n",
        "  \n",
        "plt.scatter(U[:, 0], U[:, 1], alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFKCAYAAADWhMzpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "JX9D_9f2nmRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "e979be94-2822-47bf-bfbe-f6a96081792b"
      },
      "cell_type": "code",
      "source": [
        "# PTBデータセットをインポート\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "import urllib.request\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "url_base = 'https://raw.githubusercontent.com/tomsercu/lstm/master/data/'\n",
        "key_file = {\n",
        "    'train':'ptb.train.txt',\n",
        "    'test':'ptb.test.txt',\n",
        "    'valid':'ptb.valid.txt'\n",
        "}\n",
        "save_file = {\n",
        "    'train':'ptb.train.npy',\n",
        "    'test':'ptb.test.npy',\n",
        "    'valid':'ptb.valid.npy'\n",
        "}\n",
        "vocab_file = 'ptb.vocab.pkl'\n",
        "\n",
        "dataset_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + '/' + file_name\n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print('Downloading ' + file_name + ' ... ')\n",
        "\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "    except urllib.error.URLError:\n",
        "        import ssl\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "        urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "\n",
        "    print('Done')\n",
        "\n",
        "\n",
        "def load_vocab():\n",
        "    vocab_path = dataset_dir + '/' + vocab_file\n",
        "\n",
        "    if os.path.exists(vocab_path):\n",
        "        with open(vocab_path, 'rb') as f:\n",
        "            word_to_id, id_to_word = pickle.load(f)\n",
        "        return word_to_id, id_to_word\n",
        "\n",
        "    word_to_id = {}\n",
        "    id_to_word = {}\n",
        "    data_type = 'train'\n",
        "    file_name = key_file[data_type]\n",
        "    file_path = dataset_dir + '/' + file_name\n",
        "\n",
        "    _download(file_name)\n",
        "\n",
        "    words = open(file_path).read().replace('\\n', '<eos>').strip().split()\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        if word not in word_to_id:\n",
        "            tmp_id = len(word_to_id)\n",
        "            word_to_id[word] = tmp_id\n",
        "            id_to_word[tmp_id] = word\n",
        "\n",
        "    with open(vocab_path, 'wb') as f:\n",
        "        pickle.dump((word_to_id, id_to_word), f)\n",
        "\n",
        "    return word_to_id, id_to_word\n",
        "\n",
        "\n",
        "def load_data(data_type='train'):\n",
        "    '''\n",
        "        :param data_type: データの種類：'train' or 'test' or 'valid (val)'\n",
        "        :return:\n",
        "    '''\n",
        "    if data_type == 'val': data_type = 'valid'\n",
        "    save_path = dataset_dir + '/' + save_file[data_type]\n",
        "\n",
        "    word_to_id, id_to_word = load_vocab()\n",
        "\n",
        "    if os.path.exists(save_path):\n",
        "        corpus = np.load(save_path)\n",
        "        return corpus, word_to_id, id_to_word\n",
        "\n",
        "    file_name = key_file[data_type]\n",
        "    file_path = dataset_dir + '/' + file_name\n",
        "    _download(file_name)\n",
        "\n",
        "    words = open(file_path).read().replace('\\n', '<eos>').strip().split()\n",
        "    corpus = np.array([word_to_id[w] for w in words])\n",
        "\n",
        "    np.save(save_path, corpus)\n",
        "    return corpus, word_to_id, id_to_word\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    for data_type in ('train', 'val', 'test'):\n",
        "        load_data(data_type)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ptb.train.txt ... \n",
            "Done\n",
            "Downloading ptb.valid.txt ... \n",
            "Done\n",
            "Downloading ptb.test.txt ... \n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QuRhHC3co5_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "a329a06f-2554-4804-fecb-ccf9861fb30c"
      },
      "cell_type": "code",
      "source": [
        "corpus, word_to_id, id_to_word = load_data('train')\n",
        "\n",
        "print('corpus size:', len(corpus))\n",
        "print('corpus[:30]:', corpus[:30])\n",
        "print()\n",
        "print('id_to_word[0]:', id_to_word[0])\n",
        "print('id_to_word[1]:', id_to_word[1])\n",
        "print('id_to_word[2]:', id_to_word[2])\n",
        "print()\n",
        "print(\"word_to_id['car']:\", word_to_id['car'])\n",
        "print(\"word_to_id['happy']\", word_to_id['happy'])\n",
        "print(\"word_to_id['lexus']\", word_to_id['lexus'])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus size: 929589\n",
            "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "id_to_word[0]: aer\n",
            "id_to_word[1]: banknote\n",
            "id_to_word[2]: berlitz\n",
            "\n",
            "word_to_id['car']: 3856\n",
            "word_to_id['happy'] 4428\n",
            "word_to_id['lexus'] 7426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8I8binXgpz1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2375
        },
        "outputId": "d0ac06cb-44ce-4adb-92ae-30b050fa2322"
      },
      "cell_type": "code",
      "source": [
        "window_size = 2\n",
        "wordvec_size = 100\n",
        "corpus, word_to_id, id_to_word = load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "print('counting co-occurrence ...')\n",
        "C = create_co_matrix(corpus, vocab_size, window_size)\n",
        "print('calculating PPMI ...')\n",
        "W = ppmi(C, verbose=True)\n",
        "\n",
        "print('calculating SVD ...')\n",
        "try:\n",
        "  # truncated SVD (fast!)\n",
        "  from sklearn.utils.extmath import randomized_svd\n",
        "  U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5, random_state=None)\n",
        "except ImportError:\n",
        "  # SVD (slow)\n",
        "  U, S, V = np.linalg.svd(W)\n",
        "\n",
        "word_vecs = U[:, :wordvec_size]\n",
        "\n",
        "querys = ['you', 'year', 'car', 'toyota']\n",
        "for query in querys:\n",
        "  most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counting co-occurrence ...\n",
            "calculating PPMI ...\n",
            "1.0% done\n",
            "2.0% done\n",
            "3.0% done\n",
            "4.0% done\n",
            "5.0% done\n",
            "6.0% done\n",
            "7.0% done\n",
            "8.0% done\n",
            "9.0% done\n",
            "10.0% done\n",
            "11.0% done\n",
            "12.0% done\n",
            "13.0% done\n",
            "14.0% done\n",
            "15.0% done\n",
            "16.0% done\n",
            "17.0% done\n",
            "18.0% done\n",
            "19.0% done\n",
            "20.0% done\n",
            "21.0% done\n",
            "22.0% done\n",
            "23.0% done\n",
            "24.0% done\n",
            "25.0% done\n",
            "26.0% done\n",
            "27.0% done\n",
            "28.0% done\n",
            "29.0% done\n",
            "30.0% done\n",
            "31.0% done\n",
            "32.0% done\n",
            "33.0% done\n",
            "34.0% done\n",
            "35.0% done\n",
            "36.0% done\n",
            "37.0% done\n",
            "38.0% done\n",
            "39.0% done\n",
            "40.0% done\n",
            "41.0% done\n",
            "42.0% done\n",
            "43.0% done\n",
            "44.0% done\n",
            "45.0% done\n",
            "46.0% done\n",
            "47.0% done\n",
            "48.0% done\n",
            "49.0% done\n",
            "50.0% done\n",
            "51.0% done\n",
            "52.0% done\n",
            "53.0% done\n",
            "54.0% done\n",
            "55.0% done\n",
            "56.0% done\n",
            "57.0% done\n",
            "58.0% done\n",
            "59.0% done\n",
            "60.0% done\n",
            "61.0% done\n",
            "62.0% done\n",
            "63.0% done\n",
            "64.0% done\n",
            "65.0% done\n",
            "66.0% done\n",
            "67.0% done\n",
            "68.0% done\n",
            "69.0% done\n",
            "70.0% done\n",
            "71.0% done\n",
            "72.0% done\n",
            "73.0% done\n",
            "74.0% done\n",
            "75.0% done\n",
            "76.0% done\n",
            "77.0% done\n",
            "78.0% done\n",
            "79.0% done\n",
            "80.0% done\n",
            "81.0% done\n",
            "82.0% done\n",
            "83.0% done\n",
            "84.0% done\n",
            "85.0% done\n",
            "86.0% done\n",
            "87.0% done\n",
            "88.0% done\n",
            "89.0% done\n",
            "90.0% done\n",
            "91.0% done\n",
            "92.0% done\n",
            "93.0% done\n",
            "94.0% done\n",
            "95.0% done\n",
            "96.0% done\n",
            "97.0% done\n",
            "98.0% done\n",
            "99.0% done\n",
            "100.0% done\n",
            "calculating SVD ...\n",
            "\n",
            "[query] you\n",
            " i: 0.6421951651573181\n",
            " we: 0.6153792142868042\n",
            " do: 0.5580697059631348\n",
            " anybody: 0.5183548927307129\n",
            " something: 0.5155536532402039\n",
            "\n",
            "[query] year\n",
            " quarter: 0.6292266845703125\n",
            " fiscal: 0.6271905303001404\n",
            " month: 0.6252601146697998\n",
            " earlier: 0.6194627285003662\n",
            " next: 0.5879861116409302\n",
            "\n",
            "[query] car\n",
            " auto: 0.6305562257766724\n",
            " luxury: 0.5868212580680847\n",
            " truck: 0.5515871644020081\n",
            " cars: 0.5304639339447021\n",
            " corsica: 0.47708821296691895\n",
            "\n",
            "[query] toyota\n",
            " motor: 0.7581999897956848\n",
            " motors: 0.6678661108016968\n",
            " nissan: 0.6676543354988098\n",
            " lexus: 0.6629056930541992\n",
            " mazda: 0.6291062831878662\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}